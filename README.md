# ğŸ§  Local Obsidian AI Agent (MVP)

Este projeto implementa um **Agente de IA totalmente local** capaz de interagir com seu cofre (Vault) do Obsidian. Ele utiliza um modelo LLM rodando via `llama.cpp` para raciocinar (ReAct) e um servidor MCP (FastAPI) para executar aÃ§Ãµes reais nas suas notas.

> **âš ï¸ STATUS DO PROJETO: Alpha / VersÃ£o BÃ¡sica**
> Este Ã© um MVP (MÃ­nimo Produto ViÃ¡vel).
> **Features:** Agente ReAct, Ferramentas de Leitura/Escrita no Obsidian.
> **Stack:** Python, uv, Llama.cpp (GPU), FastAPI.

## ğŸ“‹ PrÃ©-requisitos

1.  **Gerenciador de Pacotes `uv`**: [Instalar uv](https://github.com/astral-sh/uv).
2.  **Obsidian**: Com o plugin **Local REST API** instalado e ativo.
3.  **Hardware**: Recomendado **GPU NVIDIA** (Drivers e CUDA Toolkit instalados).
4.  **Make**: Ferramenta de build (padrÃ£o no Linux/WSL. No Windows, use WSL ou instale via chocolatey).
5.  **Modelo GGUF**: Um modelo `.gguf` (Recomendado: *Qwen 2.5* ou *Llama 3.1* Instruct).

---

## ğŸ› ï¸ InstalaÃ§Ã£o Simplificada

### 1. Configurar o Obsidian
1.  No Obsidian, vÃ¡ em **Settings > Community Plugins > Browse**.
2.  Instale o plugin **Local REST API**.
3.  Habilite o plugin e copie o **API Key** (Token).

### 2. Configurar o Projeto
Este projeto usa um `Makefile` para garantir que o suporte a GPU seja compilado corretamente.

1.  Clone este repositÃ³rio.
2.  Execute a instalaÃ§Ã£o:

    ```bash
    make install
    ```
    *Isso vai criar o ambiente virtual, baixar as libs e compilar o llama.cpp usando sua placa de vÃ­deo.*

### 3. Configurar VariÃ¡veis (.env)
Crie um arquivo `.env` na raiz:

```ini
# Obsidian Config (Local REST API)
OBSIDIAN_API_URL=[http://127.0.0.1:27123](http://127.0.0.1:27123)
OBSIDIAN_API_TOKEN=seu_token_aqui

# Caminho absoluto para seu modelo .gguf
MODEL_PATH=/home/usuario/ai/models/Qwen2.5-7B-Instruct-Q4_K_M.gguf

# Servidor MCP (PadrÃ£o)
MCP_URL=http://localhost:8080/tools/call
````

-----

## ğŸš€ Como Usar

Abra dois terminais na pasta do projeto.

**Terminal 1: Iniciar o Servidor**

```bash
make server
```

**Terminal 2: Iniciar o Agente**

```bash
make agent
```

**Exemplo de interaÃ§Ã£o:**

> **VocÃª:** "Verifique se tenho alguma nota sobre 'Receitas' e, se nÃ£o tiver, crie uma com uma lista de ingredientes para bolo."
>
> **Agente:** (O agente vai buscar, nÃ£o encontrar, e entÃ£o criar a nota).

-----

## ğŸ“¦ GestÃ£o de DependÃªncias

Se precisar adicionar novas bibliotecas (ex: numpy), use:

```bash
uv add numpy
```

*Nota: O `llama-cpp-python` nÃ£o deve ser atualizado via `uv sync` puro para nÃ£o perder o suporte a GPU. Se precisar reinstalÃ¡-lo, rode `make install` novamente.*

-----

## ğŸ—ºï¸ Roadmap

  - [ ] **RAG (MemÃ³ria):** Ler notas antigas para contexto.
  - [ ] **Multi-Agentes:** Especialistas em tarefas distintas (escrita, organizaÃ§Ã£o, etc..)
  - [ ] **Prompt Template:** Melhorar o System Prompt para evitar alucinaÃ§Ãµes de JSON.
  - [] **CriaÃ§Ã£o de Tools** Capacidade de criar novas tools.
  - [] **Interface de configuraÃ§Ã£o** Jeito fÃ¡cil de trocar prompts e modelos.

-----

## ğŸ†˜ Troubleshooting

  * **Erro `make: command not found`**: Instale o pacote `build-essential` (Ubuntu/Debian) ou use WSL no Windows.
  * **LentidÃ£o Extrema**: Verifique se o modelo foi carregado na GPU olhando os logs do `make agent`. Se aparecer `BLAS = 0`, rode `make install` novamente.